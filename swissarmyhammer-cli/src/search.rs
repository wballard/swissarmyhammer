use anyhow::Result;
use colored::*;
use is_terminal::IsTerminal;
use std::io;
use tabled::{
    settings::{object::Rows, Alignment, Color, Modify, Style},
    Table, Tabled,
};

use crate::cli::{OutputFormat, PromptSource, PromptSourceArg, SearchCommands};
use crate::mcp_integration::{response_formatting, CliToolContext};
use serde_json::json;
use swissarmyhammer::{
    prelude::{AdvancedSearchEngine, AdvancedSearchOptions},
    PromptFilter, PromptLibrary, PromptResolver,
};

// UI constants (kept for potential future use)

#[derive(Debug, Clone, serde::Serialize)]
pub struct SearchResult {
    pub name: String,
    pub title: Option<String>,
    pub description: Option<String>,
    pub source: String,
    pub score: f32,
    pub excerpt: Option<String>,
    pub arguments: Vec<SearchArgument>,
}

#[derive(Debug, Clone, serde::Serialize)]
pub struct SearchArgument {
    pub name: String,
    pub description: Option<String>,
    pub required: bool,
    pub default: Option<String>,
}

#[derive(Tabled)]
struct SearchResultRow {
    #[tabled(rename = "Name")]
    name: String,
    #[tabled(rename = "Title")]
    title: String,
    #[tabled(rename = "Excerpt")]
    excerpt: String,
    #[tabled(rename = "Source")]
    source: String,
    #[tabled(rename = "Score")]
    score: String,
}

#[allow(clippy::too_many_arguments)]
pub fn run_search_command(
    query: String,
    _fields: Option<Vec<String>>,
    regex: bool,
    fuzzy: bool,
    case_sensitive: bool,
    source_filter: Option<PromptSourceArg>,
    has_arg: Option<String>,
    no_args: bool,
    full: bool,
    format: OutputFormat,
    highlight: bool,
    limit: Option<usize>,
) -> Result<()> {
    // Load all prompts from all sources
    let mut library = PromptLibrary::new();
    let mut resolver = PromptResolver::new();
    resolver.load_all_prompts(&mut library)?;

    // Get all prompts
    let all_prompts = library.list()?;

    // Create advanced search options
    let search_options = AdvancedSearchOptions {
        regex,
        fuzzy,
        case_sensitive,
        highlight,
        limit,
    };

    // Create filter based on CLI options
    let mut filter = PromptFilter::new();

    // Apply source filter
    if let Some(ref src_filter) = source_filter {
        let library_source: PromptSource = src_filter.clone().into();
        filter = filter.with_source(library_source);
    }

    // Apply argument filters
    if let Some(arg_name) = has_arg {
        filter = filter.with_has_arg(arg_name);
    }

    if no_args {
        filter = filter.with_no_args(true);
    }

    // Perform search using advanced search engine
    let search_engine = AdvancedSearchEngine::new()?;
    let search_results = search_engine.search(
        &query,
        &all_prompts,
        &search_options,
        Some(&filter),
        &resolver.prompt_sources,
    )?;

    // Convert results to CLI format
    let results: Vec<SearchResult> = search_results
        .into_iter()
        .map(|result| {
            // Get the source from the resolver
            let prompt_source = match resolver.prompt_sources.get(&result.prompt.name) {
                Some(PromptSource::Builtin) => PromptSource::Builtin,
                Some(PromptSource::User) => PromptSource::User,
                Some(PromptSource::Local) => PromptSource::Local,
                Some(PromptSource::Dynamic) => PromptSource::Dynamic,
                None => PromptSource::Dynamic,
            };
            let source_str = prompt_source.to_string();

            let arguments = result
                .prompt
                .arguments
                .iter()
                .map(|arg| SearchArgument {
                    name: arg.name.clone(),
                    description: arg.description.clone(),
                    required: arg.required,
                    default: arg.default.clone(),
                })
                .collect();

            SearchResult {
                name: result.prompt.name.clone(),
                title: None, // No title field in new API
                description: result.prompt.description.clone(),
                source: source_str,
                score: result.score,
                excerpt: result.excerpt,
                arguments,
            }
        })
        .collect();

    // Output results
    match format {
        OutputFormat::Json => {
            let json = serde_json::to_string_pretty(&results)?;
            println!("{json}");
        }
        OutputFormat::Yaml => {
            let yaml = serde_yaml::to_string(&results)?;
            print!("{yaml}");
        }
        OutputFormat::Table => {
            display_table(&results, full)?;
        }
    }

    Ok(())
}

fn display_table(results: &[SearchResult], full: bool) -> Result<()> {
    if results.is_empty() {
        println!("No prompts found matching the search criteria.");
        return Ok(());
    }

    let is_tty = io::stdout().is_terminal();

    let rows: Vec<SearchResultRow> = results
        .iter()
        .map(|result| {
            let title = result.title.as_deref().unwrap_or("");
            let excerpt = if full {
                result.excerpt.as_deref().unwrap_or("")
            } else {
                // Truncate long excerpts for table display
                let exc = result.excerpt.as_deref().unwrap_or("");
                if exc.len() > 50 {
                    &format!("{}...", &exc[..47])
                } else {
                    exc
                }
            };

            SearchResultRow {
                name: result.name.clone(),
                title: title.to_string(),
                excerpt: excerpt.to_string(),
                source: result.source.clone(),
                score: format!("{:.1}", result.score),
            }
        })
        .collect();

    let mut table = Table::new(rows);
    table.with(Style::modern());

    if is_tty {
        // Add colors for better readability in terminal
        // tabled 0.20+ changed API: Rows::single() â†’ Rows::one()
        table.with(Modify::new(Rows::one(0)).with(Color::FG_BRIGHT_CYAN));

        // Color code sources
        for (i, result) in results.iter().enumerate() {
            let row_index = i + 1; // +1 because row 0 is header
            match result.source.as_str() {
                "builtin" => {
                    table.with(Modify::new(Rows::one(row_index)).with(Color::FG_GREEN));
                }
                "user" => {
                    table.with(Modify::new(Rows::one(row_index)).with(Color::FG_BLUE));
                }
                "local" => {
                    table.with(Modify::new(Rows::one(row_index)).with(Color::FG_YELLOW));
                }
                _ => {}
            }
        }
    }

    table.with(Modify::new(Rows::new(1..)).with(Alignment::left()));

    println!("{table}");

    if is_tty && !results.is_empty() {
        println!();
        println!("{} results found", results.len());
    }

    Ok(())
}

pub fn generate_excerpt(content: &str, query: &str, highlight: bool) -> Option<String> {
    let query_lower = query.to_lowercase();
    let content_lower = content.to_lowercase();

    if let Some(pos) = content_lower.find(&query_lower) {
        let start = pos.saturating_sub(30);
        let end = (pos + query.len() + 30).min(content.len());

        let excerpt = &content[start..end];

        if highlight {
            let highlighted = excerpt.replace(query, &format!("{}", query.bright_yellow()));
            Some(format!("...{highlighted}..."))
        } else {
            Some(format!("...{excerpt}..."))
        }
    } else {
        None
    }
}

#[allow(dead_code)]
pub fn generate_excerpt_with_long_text(content: &str, query: &str, max_length: usize) -> String {
    let excerpt = generate_excerpt(content, query, false).unwrap_or_default();
    if excerpt.len() > max_length {
        format!("{}...", &excerpt[..max_length.saturating_sub(3)])
    } else {
        excerpt
    }
}

/// Run semantic search commands
pub async fn run_search(subcommand: SearchCommands) -> i32 {
    use crate::exit_codes::{EXIT_ERROR, EXIT_SUCCESS};

    match subcommand {
        SearchCommands::Index { patterns, force } => {
            match run_semantic_index(&patterns, force).await {
                Ok(()) => EXIT_SUCCESS,
                Err(e) => {
                    eprintln!("{}", format!("âŒ Indexing failed: {e}").red());
                    EXIT_ERROR
                }
            }
        }
        SearchCommands::Query {
            query,
            limit,
            format,
        } => match run_semantic_query_with_format(&query, limit, format).await {
            Ok(()) => EXIT_SUCCESS,
            Err(e) => {
                eprintln!("{}", format!("âŒ Search failed: {e}").red());
                EXIT_ERROR
            }
        },
    }
}

/// Run semantic indexing for the given patterns using MCP tools
async fn run_semantic_index(patterns: &[String], force: bool) -> Result<()> {
    println!("{}", "ðŸ” Starting semantic search indexing...".cyan());

    if patterns.is_empty() {
        return Err(anyhow::anyhow!(
            "No patterns or files provided for indexing. Please specify one or more glob patterns (like '**/*.rs') or file paths."
        ));
    }

    // For backward compatibility with tests, show different message based on pattern count
    if patterns.len() == 1 {
        println!("Indexing files matching: {}", patterns[0].bright_yellow());
    } else {
        println!(
            "Indexing patterns/files: {}",
            patterns.join(", ").bright_yellow()
        );
    }
    if force {
        println!("{}", "Force re-indexing: enabled".yellow());
    }

    // Use MCP tool for indexing
    let context = CliToolContext::new()
        .await
        .map_err(|e| anyhow::anyhow!("Failed to create CLI context: {}", e))?;
    let args =
        context.create_arguments(vec![("patterns", json!(patterns)), ("force", json!(force))]);

    let result = context
        .execute_tool("search_index", args)
        .await
        .map_err(|e| anyhow::anyhow!("Failed to execute search_index MCP tool: {}. Ensure the swissarmyhammer MCP server is running and accessible.", e))?;
    search_response_formatting::format_index_response(&result)
        .map_err(|e| anyhow::anyhow!("Failed to format response: {}", e))?;

    Ok(())
}

/// Run semantic query search using MCP tools with format
async fn run_semantic_query_with_format(
    query: &str,
    limit: usize,
    format: OutputFormat,
) -> Result<()> {
    // Use MCP tool for querying
    let context = CliToolContext::new()
        .await
        .map_err(|e| anyhow::anyhow!("Failed to create CLI context: {}", e))?;
    let args = context.create_arguments(vec![("query", json!(query)), ("limit", json!(limit))]);

    let result = context
        .execute_tool("search_query", args)
        .await
        .map_err(|e| anyhow::anyhow!("Failed to execute search_query MCP tool: {}. Ensure the search index exists (run 'sh search index' first) and the swissarmyhammer MCP server is running.", e))?;
    search_response_formatting::format_query_results(&result, format)
        .map_err(|e| anyhow::anyhow!("Failed to format response: {}", e))?;

    Ok(())
}

/// Run semantic query search using MCP tools (backward compatibility)
#[allow(dead_code)]
async fn run_semantic_query(query: &str, limit: usize) -> Result<()> {
    run_semantic_query_with_format(query, limit, OutputFormat::Table).await
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_generate_excerpt() {
        let content = "This is a test content with some keywords in it";
        let query = "keywords";

        let excerpt = generate_excerpt(content, query, false);
        assert!(excerpt.is_some());
        assert!(excerpt.unwrap().contains("keywords"));
    }

    #[test]
    fn test_generate_excerpt_with_long_text() {
        let content = "This is a very long test content with some keywords that we want to find and excerpt properly";
        let query = "keywords";

        let excerpt = generate_excerpt_with_long_text(content, query, 50);
        assert!(excerpt.len() <= 50);
        assert!(excerpt.contains("..."));
    }

    #[test]
    fn test_search_result_creation() {
        let result = SearchResult {
            name: "test-prompt".to_string(),
            title: Some("Test Prompt".to_string()),
            description: Some("A test prompt".to_string()),
            source: "local".to_string(),
            score: 100.0,
            excerpt: None,
            arguments: vec![],
        };

        assert_eq!(result.name, "test-prompt");
        assert_eq!(result.score, 100.0);
    }

    #[tokio::test]
    #[ignore] // Temporarily disabled due to DuckDB crash during cleanup
    async fn test_run_semantic_index_empty_patterns() {
        let patterns: Vec<String> = vec![];
        let result = run_semantic_index(&patterns, false).await;
        assert!(result.is_err());
        assert!(result
            .unwrap_err()
            .to_string()
            .contains("No patterns or files provided"));
    }

    #[tokio::test]
    #[ignore] // Temporarily disabled due to DuckDB crash during cleanup
    async fn test_run_semantic_index_single_pattern() {
        let patterns = vec!["test_pattern.rs".to_string()];

        // Semantic indexing should work with fastembed's automatic model caching
        // Models will be downloaded on first run and cached for subsequent runs
        // However, in test environments without network access or proper cache setup,
        // model initialization may fail - this is expected and acceptable
        match run_semantic_index(&patterns, false).await {
            Ok(_) => {
                println!("âœ… Semantic indexing succeeded as expected");
            }
            Err(e) => {
                let error_msg = e.to_string();
                if error_msg.contains("Failed to initialize fastembed model")
                    || error_msg.contains("I/O error")
                    || error_msg.contains("No such file or directory")
                {
                    println!("âš ï¸  Semantic indexing skipped - model initialization failed in test environment: {error_msg}");
                    println!("   This is expected when fastembed models cannot be downloaded (offline/restricted environment)");
                } else {
                    panic!("Unexpected error in semantic indexing: {error_msg}");
                }
            }
        }
    }

    #[tokio::test]
    #[ignore] // Temporarily disabled due to DuckDB crash during cleanup
    async fn test_run_semantic_index_multiple_patterns() {
        let patterns = vec![
            "src/**/*.rs".to_string(),
            "tests/**/*.rs".to_string(),
            "benches/**/*.rs".to_string(),
        ];

        // Semantic indexing should work with fastembed's automatic model caching
        // Models will be downloaded on first run and cached for subsequent runs
        // However, in test environments without network access or proper cache setup,
        // model initialization may fail - this is expected and acceptable
        match run_semantic_index(&patterns, false).await {
            Ok(_) => {
                println!("âœ… Semantic indexing succeeded as expected");
            }
            Err(e) => {
                let error_msg = e.to_string();
                if error_msg.contains("Failed to initialize fastembed model")
                    || error_msg.contains("I/O error")
                    || error_msg.contains("No such file or directory")
                {
                    println!("âš ï¸  Semantic indexing skipped - model initialization failed in test environment: {error_msg}");
                    println!("   This is expected when fastembed models cannot be downloaded (offline/restricted environment)");
                } else {
                    panic!("Unexpected error in semantic indexing: {error_msg}");
                }
            }
        }
    }

    #[test]
    fn test_file_line_format() {
        // Test that file:line format is correctly structured
        use std::path::PathBuf;
        use swissarmyhammer::search::{ChunkType, CodeChunk, ContentHash, Language};

        let chunk = CodeChunk {
            id: "test-chunk".to_string(),
            file_path: PathBuf::from("./src/main.rs"),
            language: Language::Rust,
            content: "fn main() {}".to_string(),
            start_line: 42,
            end_line: 45,
            chunk_type: ChunkType::Function,
            content_hash: ContentHash("hash123".to_string()),
        };

        // Test the format string that would be used in the display
        let formatted_result = format!("{}:{}", chunk.file_path.display(), chunk.start_line);
        assert_eq!(formatted_result, "./src/main.rs:42");

        // Test with a different path format
        let chunk2 = CodeChunk {
            id: "test-chunk-2".to_string(),
            file_path: PathBuf::from("tests/integration.rs"),
            language: Language::Rust,
            content: "#[test] fn test() {}".to_string(),
            start_line: 123,
            end_line: 125,
            chunk_type: ChunkType::Function,
            content_hash: ContentHash("hash456".to_string()),
        };

        let formatted_result2 = format!("{}:{}", chunk2.file_path.display(), chunk2.start_line);
        assert_eq!(formatted_result2, "tests/integration.rs:123");
    }
}

/// Search-specific response formatting for MCP tool results
mod search_response_formatting {
    use super::*;
    use rmcp::model::CallToolResult;

    /// Format index response from MCP search_index tool
    pub fn format_index_response(
        result: &CallToolResult,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let json_data = response_formatting::extract_json_data(result)?;

        let indexed_files = json_data
            .get("indexed_files")
            .and_then(|v| v.as_u64())
            .unwrap_or(0);
        let skipped_files = json_data
            .get("skipped_files")
            .and_then(|v| v.as_u64())
            .unwrap_or(0);
        let total_chunks = json_data
            .get("total_chunks")
            .and_then(|v| v.as_u64())
            .unwrap_or(0);
        let execution_time = json_data
            .get("execution_time_ms")
            .and_then(|v| v.as_u64())
            .unwrap_or(0);

        // Match the exact formatting from the original implementation
        println!("\n{}", "âœ… Indexing completed!".green().bold());
        println!("Duration: {:.2}s", (execution_time as f32) / 1000.0);

        // Create summary matching original format
        let mut summary_parts = Vec::new();
        if indexed_files > 0 {
            summary_parts.push(format!("{indexed_files} files indexed"));
        }
        if total_chunks > 0 {
            summary_parts.push(format!("{total_chunks} chunks generated"));
        }
        if skipped_files > 0 {
            summary_parts.push(format!("{skipped_files} files skipped"));
        }

        if !summary_parts.is_empty() {
            println!("{}", summary_parts.join(", ").bright_cyan());
        }

        Ok(())
    }

    /// Format query results from MCP search_query tool
    pub fn format_query_results(
        result: &CallToolResult,
        format: OutputFormat,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let json_data = response_formatting::extract_json_data(result)?;

        match format {
            OutputFormat::Json => {
                println!("{}", serde_json::to_string_pretty(&json_data)?);
            }
            OutputFormat::Yaml => {
                println!("{}", serde_yaml::to_string(&json_data)?);
            }
            OutputFormat::Table => {
                format_query_results_table(&json_data)?;
            }
        }

        Ok(())
    }

    /// Format query results as table matching original CLI behavior
    fn format_query_results_table(
        data: &serde_json::Value,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let empty_vec = vec![];
        let results = data
            .get("results")
            .and_then(|v| v.as_array())
            .unwrap_or(&empty_vec);
        let query = data.get("query").and_then(|v| v.as_str()).unwrap_or("");
        let execution_time = data
            .get("execution_time_ms")
            .and_then(|v| v.as_u64())
            .unwrap_or(0);

        // Match original formatting exactly
        println!("{}", "ðŸ” Starting semantic search query...".cyan());
        println!("Searching for: {}", query.bright_yellow());

        if results.is_empty() {
            println!("\n{}", "No matches found.".yellow());
        } else {
            println!(
                "\n{}",
                format!("âœ… Found {} results!", results.len())
                    .green()
                    .bold()
            );
            println!("Search duration: {:.2}s", (execution_time as f32) / 1000.0);
            println!();

            for (i, result) in results.iter().enumerate() {
                if let Some(result_obj) = result.as_object() {
                    let file_path = result_obj
                        .get("file_path")
                        .and_then(|v| v.as_str())
                        .unwrap_or("unknown");
                    let similarity = result_obj
                        .get("similarity_score")
                        .and_then(|v| v.as_f64())
                        .unwrap_or(0.0);
                    let line_start = result_obj
                        .get("line_start")
                        .and_then(|v| v.as_u64())
                        .unwrap_or(0);

                    // Match original color coding logic
                    let score_color = if similarity > 0.8 {
                        "green"
                    } else if similarity > 0.6 {
                        "yellow"
                    } else {
                        "white"
                    };

                    println!(
                        "{}",
                        format!(
                            "{}. {}:{} (score: {:.3})",
                            i + 1,
                            file_path,
                            line_start,
                            similarity
                        )
                        .color(score_color)
                    );

                    // Show excerpt matching original format
                    if let Some(excerpt) = result_obj.get("excerpt").and_then(|v| v.as_str()) {
                        let excerpt = excerpt.trim();
                        if !excerpt.is_empty() {
                            for line in excerpt.lines() {
                                println!("   {}", line.dimmed());
                            }
                        }
                    }
                    println!();
                }
            }
        }

        Ok(())
    }
}
