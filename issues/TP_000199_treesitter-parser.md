# TP_000199: TreeSitter Code Parser Implementation  

## Goal
Implement TreeSitter-based code parsing for supported languages to extract semantic chunks (functions, classes, modules).

## Context
The specification requires using TreeSitter to parse source files for supported languages and extract type and function level chunks. This enables more meaningful semantic search compared to naive text chunking.

## Specification Requirements
- Use TreeSitter https://crates.io/crates/tree-sitter to parse source files
- Support: rust, python, typescript, javascript, dart
- If a file fails to parse with TreeSitter, log a warning and treat it as plain text

## Tasks

### 1. Create CodeParser in `semantic/parser.rs`

```rust
use crate::semantic::{Result, SemanticError, Language, CodeChunk, ChunkType, ContentHash};
use crate::semantic::utils::FileHasher;
use std::path::Path;
use tree_sitter::{Parser, Tree, Node, Query, QueryCursor};

pub struct CodeParser {
    rust_parser: Option<Parser>,
    python_parser: Option<Parser>, 
    typescript_parser: Option<Parser>,
    javascript_parser: Option<Parser>,
    dart_parser: Option<Parser>,
}

impl CodeParser {
    pub fn new() -> Result<Self> {
        Ok(Self {
            rust_parser: Self::create_rust_parser(),
            python_parser: Self::create_python_parser(),
            typescript_parser: Self::create_typescript_parser(),  
            javascript_parser: Self::create_javascript_parser(),
            dart_parser: Self::create_dart_parser(),
        })
    }
    
    fn create_rust_parser() -> Option<Parser> {
        let mut parser = Parser::new();
        match parser.set_language(&tree_sitter_rust::language()) {
            Ok(_) => Some(parser),
            Err(e) => {
                tracing::warn!("Failed to initialize Rust parser: {}", e);
                None
            }
        }
    }
    
    fn create_python_parser() -> Option<Parser> {
        let mut parser = Parser::new();
        match parser.set_language(&tree_sitter_python::language()) {
            Ok(_) => Some(parser),
            Err(e) => {
                tracing::warn!("Failed to initialize Python parser: {}", e);
                None
            }
        }
    }
    
    fn create_typescript_parser() -> Option<Parser> {
        let mut parser = Parser::new();
        match parser.set_language(&tree_sitter_typescript::language_typescript()) {
            Ok(_) => Some(parser),
            Err(e) => {
                tracing::warn!("Failed to initialize TypeScript parser: {}", e);
                None
            }
        }
    }
    
    fn create_javascript_parser() -> Option<Parser> {
        let mut parser = Parser::new();
        match parser.set_language(&tree_sitter_javascript::language()) {
            Ok(_) => Some(parser),
            Err(e) => {
                tracing::warn!("Failed to initialize JavaScript parser: {}", e);
                None
            }
        }
    }
    
    fn create_dart_parser() -> Option<Parser> {
        let mut parser = Parser::new();
        match parser.set_language(&tree_sitter_dart::language()) {
            Ok(_) => Some(parser),
            Err(e) => {
                tracing::warn!("Failed to initialize Dart parser: {}", e);
                None
            }
        }
    }
}
```

### 2. Language Detection

```rust
impl CodeParser {
    /// Detect programming language from file extension
    pub fn detect_language(file_path: &Path) -> Language {
        match file_path.extension().and_then(|ext| ext.to_str()) {
            Some("rs") => Language::Rust,
            Some("py") | Some("pyx") | Some("pyi") => Language::Python,
            Some("ts") | Some("tsx") => Language::TypeScript,
            Some("js") | Some("jsx") | Some("mjs") => Language::JavaScript,
            Some("dart") => Language::Dart,
            _ => Language::Unknown,
        }
    }
    
    /// Get appropriate parser for language
    fn get_parser_for_language(&mut self, language: &Language) -> Option<&mut Parser> {
        match language {
            Language::Rust => self.rust_parser.as_mut(),
            Language::Python => self.python_parser.as_mut(),
            Language::TypeScript => self.typescript_parser.as_mut(),
            Language::JavaScript => self.javascript_parser.as_mut(), 
            Language::Dart => self.dart_parser.as_mut(),
            Language::Unknown => None,
        }
    }
}
```

### 3. TreeSitter Query Definitions

```rust
impl CodeParser {
    /// Get TreeSitter queries for extracting semantic chunks
    fn get_queries_for_language(language: &Language) -> Vec<(&'static str, ChunkType)> {
        match language {
            Language::Rust => vec![
                // Functions
                ("(function_item name: (identifier) @name body: (_)) @function", ChunkType::Function),
                // Impl blocks  
                ("(impl_item type: (_) @type body: (_)) @impl", ChunkType::Class),
                // Structs
                ("(struct_item name: (type_identifier) @name) @struct", ChunkType::Class),
                // Enums
                ("(enum_item name: (type_identifier) @name) @enum", ChunkType::Class),
                // Use statements
                ("(use_declaration) @import", ChunkType::Import),
            ],
            Language::Python => vec![
                // Functions
                ("(function_definition name: (identifier) @name) @function", ChunkType::Function),
                // Classes
                ("(class_definition name: (identifier) @name) @class", ChunkType::Class),
                // Import statements
                ("(import_statement) @import", ChunkType::Import),
                ("(import_from_statement) @import", ChunkType::Import),
            ],
            Language::TypeScript | Language::JavaScript => vec![
                // Functions
                ("(function_declaration name: (identifier) @name) @function", ChunkType::Function),
                // Arrow functions
                ("(arrow_function) @function", ChunkType::Function),
                // Classes
                ("(class_declaration name: (type_identifier) @name) @class", ChunkType::Class),
                // Import statements
                ("(import_statement) @import", ChunkType::Import),
            ],
            Language::Dart => vec![
                // Functions
                ("(function_signature name: (identifier) @name) @function", ChunkType::Function),
                // Classes
                ("(class_definition name: (type_identifier) @name) @class", ChunkType::Class),
                // Import statements
                ("(import_or_export) @import", ChunkType::Import),
            ],
            Language::Unknown => vec![],
        }
    }
}
```

### 4. Main Parsing Logic

```rust
impl CodeParser {
    /// Parse file and extract semantic chunks
    pub fn parse_file(&mut self, file_path: &Path) -> Result<Vec<CodeChunk>> {
        let content = std::fs::read_to_string(file_path)?;
        let language = Self::detect_language(file_path);
        
        // Try TreeSitter parsing first
        match self.parse_with_treesitter(file_path, &content, &language) {
            Ok(chunks) => {
                tracing::debug!(
                    "Successfully parsed {} with TreeSitter: {} chunks", 
                    file_path.display(), 
                    chunks.len()
                );
                Ok(chunks)
            }
            Err(e) => {
                // Fall back to plain text as per specification
                tracing::warn!(
                    "TreeSitter parsing failed for {}: {}. Treating as plain text.", 
                    file_path.display(), 
                    e
                );
                self.parse_as_plain_text(file_path, &content)
            }
        }
    }
    
    fn parse_with_treesitter(
        &mut self,
        file_path: &Path, 
        content: &str,
        language: &Language
    ) -> Result<Vec<CodeChunk>> {
        let parser = self.get_parser_for_language(language)
            .ok_or_else(|| SemanticError::TreeSitter(
                format!("No parser available for language: {:?}", language)
            ))?;
        
        let tree = parser.parse(content, None)
            .ok_or_else(|| SemanticError::TreeSitter(
                "Failed to parse file".to_string()
            ))?;
        
        let mut chunks = Vec::new();
        let content_hash = FileHasher::hash_string(content);
        
        // Extract semantic chunks using queries
        for (query_str, chunk_type) in Self::get_queries_for_language(language) {
            let query = Query::new(tree.language(), query_str)
                .map_err(|e| SemanticError::TreeSitter(format!("Invalid query: {}", e)))?;
            
            let mut cursor = QueryCursor::new();
            let matches = cursor.matches(&query, tree.root_node(), content.as_bytes());
            
            for query_match in matches {
                for capture in query_match.captures {
                    let node = capture.node;
                    let chunk = self.create_chunk_from_node(
                        file_path,
                        content,
                        node,
                        language.clone(),
                        chunk_type.clone(),
                        content_hash.clone(),
                    )?;
                    chunks.push(chunk);
                }
            }
        }
        
        // If no semantic chunks found, create one chunk for entire file
        if chunks.is_empty() {
            chunks.push(self.create_full_file_chunk(file_path, content, language, &content_hash)?);
        }
        
        Ok(chunks)
    }
    
    fn create_chunk_from_node(
        &self,
        file_path: &Path,
        content: &str,
        node: Node,
        language: Language,
        chunk_type: ChunkType,
        content_hash: ContentHash,
    ) -> Result<CodeChunk> {
        let start_byte = node.start_byte();
        let end_byte = node.end_byte();
        let chunk_content = &content[start_byte..end_byte];
        
        let start_pos = node.start_position();
        let end_pos = node.end_position();
        
        Ok(CodeChunk {
            id: format!("{}:{}:{}", 
                file_path.display(), 
                start_pos.row, 
                chunk_type as u8
            ),
            file_path: file_path.to_path_buf(),
            language,
            content: chunk_content.to_string(),
            start_line: start_pos.row + 1, // TreeSitter uses 0-based rows
            end_line: end_pos.row + 1,
            chunk_type,
            content_hash,
        })
    }
    
    fn parse_as_plain_text(&self, file_path: &Path, content: &str) -> Result<Vec<CodeChunk>> {
        let content_hash = FileHasher::hash_string(content);
        let language = Self::detect_language(file_path);
        
        // Create single chunk for entire file
        let chunk = self.create_full_file_chunk(file_path, content, &language, &content_hash)?;
        Ok(vec![chunk])
    }
    
    fn create_full_file_chunk(
        &self,
        file_path: &Path,
        content: &str,
        language: &Language,
        content_hash: &ContentHash,
    ) -> Result<CodeChunk> {
        let line_count = content.lines().count();
        
        Ok(CodeChunk {
            id: format!("{}:full", file_path.display()),
            file_path: file_path.to_path_buf(),
            language: language.clone(),
            content: content.to_string(),
            start_line: 1,
            end_line: line_count.max(1),
            chunk_type: ChunkType::PlainText,
            content_hash: content_hash.clone(),
        })
    }
}
```

## Acceptance Criteria
- [ ] CodeParser initializes parsers for all supported languages
- [ ] Language detection works correctly for all file extensions
- [ ] TreeSitter queries extract semantic chunks (functions, classes, imports)
- [ ] Graceful fallback to plain text when TreeSitter parsing fails
- [ ] Proper error handling and logging throughout
- [ ] Generated chunks have correct line numbers and content
- [ ] Chunk IDs are unique and meaningful
- [ ] Performance is reasonable for large files

## Architecture Notes
- Each language has dedicated TreeSitter parser instance
- Query-based extraction allows precise semantic chunk identification
- Fallback mechanism ensures no files are skipped due to parsing errors
- Chunk IDs incorporate file path and position for uniqueness
- Content hashing enables change detection at chunk level

## Testing Strategy
- Test parsing for each supported language with sample files
- Test fallback behavior with malformed source files
- Test chunk extraction accuracy with complex code structures
- Performance testing with large files

## Proposed Solution

Based on my analysis of the existing codebase, I will implement the TreeSitter-based code parser by:

1. **Enable TreeSitter dependencies**: Uncomment the TreeSitter dependencies in both workspace and library Cargo.toml files
2. **Replace placeholder implementation**: Replace the current placeholder implementation in `semantic/parser.rs` with the full TreeSitter integration as specified in the issue
3. **Maintain compatibility**: Keep the existing API surface compatible with current usage in the codebase
4. **Add comprehensive testing**: Write tests for each supported language and edge cases like parsing failures
5. **Use Test-Driven Development**: Write failing tests first, then implement functionality to make tests pass

### Implementation Steps:
1. Update CodeParser struct to hold language-specific TreeSitter parsers
2. Implement language detection and parser selection logic
3. Add TreeSitter query definitions for semantic chunk extraction
4. Implement main parsing logic with graceful fallback to plain text
5. Ensure proper error handling and logging as specified
6. Validate against all acceptance criteria

### Key Design Decisions:
- Keep existing `ParserConfig` structure for compatibility
- Use the existing semantic types (Language, CodeChunk, ChunkType, etc.)
- Maintain graceful fallback behavior when TreeSitter parsing fails
- Follow the existing error handling patterns using `Result<T>`
- Use the existing `FileHasher` utility for content hashing

## Next Steps
After completion, proceed to TP_000200_embedding-engine to implement the mistral.rs embedding generation.